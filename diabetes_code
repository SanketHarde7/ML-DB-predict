import pandas as pd

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report


df=pd.read_csv(r"C:\Users\sanke\Downloads\diabetes.csv")

x=df.drop('Outcome',axis=1)
y=df['Outcome']
# print(df.shape)
# print(df.info())
# print(df.isnull().sum())

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
from xgboost import XGBClassifier
model= XGBClassifier(use_label_encoder=False,eval_metrices='logloss')
model.fit(x_train,y_train)
y_pred=model.predict(x_test)

acc=(accuracy_score(y_test,y_pred))
print(f"accuracy :{acc*100:.2f}%")
cm=(confusion_matrix(y_test,y_pred))
print(cm)
print("classification_report:\n",classification_report(y_test,y_pred))


import seaborn as sns
import matplotlib.pylab as plt
plt.figure(figsize=(6,4))
sns.heatmap(cm,annot=True,fmt='d',cmap='Greens')
plt.xlabel("predicted")
plt.ylabel("actual")
plt.title("confusion matrix")
plt.show()

plt.bar(x.columns,model.feature_importances_)
plt.tight_layout()
plt.title("feature importances")
plt.xticks(rotation=45)
plt.show()

import joblib
joblib.dump(model,'diabetes_model.pkl')